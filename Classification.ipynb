{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "id": "51krwC5hiiiw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkG_fLYsgp8R"
      },
      "outputs": [],
      "source": [
        "#%%writefile train.py\n",
        "# Block 1: Importing all necessary dependencies\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# PyTorch and torchvision libraries for data handling and transforms\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# For visualization in Google Colab (if you're using it)\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Optionally, if you wish to clone the repo via Git in your script:\n",
        "import subprocess\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the Dataset"
      ],
      "metadata": {
        "id": "E2tw9gmbiszH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 2: Clone the GitHub repo and visualize a sample image\n",
        "# We'll clone the full repo and then use the dataset folder\n",
        "\n",
        "# Cloning using subprocess (this works in a notebook environment)\n",
        "repo_url = \"https://github.com/chandrikadeb7/Face-Mask-Detection.git\"\n",
        "subprocess.run([\"git\", \"clone\", repo_url])\n",
        "\n",
        "# Define the dataset directory (the repo contains a 'dataset' folder)\n",
        "dataset_dir = os.path.join(\"Face-Mask-Detection\", \"dataset\")\n",
        "print(\"Dataset directories:\", os.listdir(dataset_dir))\n",
        "\n",
        "# Assume two folders: 'with_mask' and 'without_mask'\n",
        "# For our assignment, we assign: with_mask -> label 0, without_mask -> label 1\n",
        "\n",
        "# Visualize a sample image from the 'with_mask' folder:\n",
        "with_mask_dir = os.path.join(dataset_dir, \"with_mask\")\n",
        "sample_img_name = os.listdir(with_mask_dir)[0]\n",
        "sample_img_path = os.path.join(with_mask_dir, sample_img_name)\n",
        "\n",
        "# Read and display the image using cv2_imshow\n",
        "sample_img = cv2.imread(sample_img_path)\n",
        "cv2_imshow(sample_img)\n",
        "print(\"Label for 'with_mask': 0\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "Uz4nnGVTinpA",
        "outputId": "1d8a6f6b-da14-4073-d189-bb040dc3eeca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset directories: ['with_mask', 'without_mask']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=114x155>"
            ],
            "image/png": "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\n",
            "image/jpeg": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label for 'with_mask': 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(len(os.listdir('/content/Face-Mask-Detection/dataset/without_mask')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2dLS2sARZo4",
        "outputId": "72b7a070-68a5-4da6-d6f4-53b09c7c6124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1930\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.feature import hog\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "!git clone https://github.com/chandrikadeb7/Face-Mask-Detection.git\n",
        "\n",
        "def extract_hog_features(image_path, target_size=(50, 50)):\n",
        "    \"\"\"Extracts HOG features from a downsampled image.\"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img_resized = cv2.resize(img, target_size)\n",
        "    features, hog_image = hog(img_resized, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
        "    return features, hog_image\n",
        "\n",
        "data_dir = \"/content/Face-Mask-Detection/dataset\"  # Replace with the actual path to your dataset\n",
        "features_list = []\n",
        "labels_list = []\n",
        "image_count = 0\n",
        "\n",
        "# Collect 10 image paths for HOG visualization\n",
        "image_paths_for_hog = []\n",
        "labels_for_hog = []\n",
        "hog_visualization_count = 0\n",
        "\n",
        "for class_name in [\"with_mask\", \"without_mask\"]:\n",
        "    class_dir = os.path.join(data_dir, class_name)\n",
        "    for filename in os.listdir(class_dir):\n",
        "        if filename.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "            image_path = os.path.join(class_dir, filename)\n",
        "            features, hog_image = extract_hog_features(image_path)\n",
        "            features_list.append(features)\n",
        "            labels_list.append(class_name)\n",
        "            image_count += 1\n",
        "\n",
        "            # Collect images for HOG visualization\n",
        "            if hog_visualization_count < 10:\n",
        "                image_paths_for_hog.append(image_path)\n",
        "                labels_for_hog.append(class_name)\n",
        "                hog_visualization_count += 1\n",
        "\n",
        "            if image_count % 1000 == 0:\n",
        "                print(f\"Processed {image_count} images...\")\n",
        "\n",
        "print(f\"Total images processed: {image_count}\")\n",
        "\n",
        "# Display HOG features for 10 images\n",
        "plt.figure(figsize=(15, 5 * len(image_paths_for_hog)))  # Adjust figure size as needed\n",
        "for i, image_path in enumerate(image_paths_for_hog):\n",
        "    features, hog_image = extract_hog_features(image_path)\n",
        "\n",
        "    # Display original image\n",
        "    plt.subplot(len(image_paths_for_hog), 2, 2 * i + 1)\n",
        "    original_image = cv2.imread(image_path)\n",
        "    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for matplotlib\n",
        "    plt.imshow(original_image)\n",
        "    plt.title(f\"Original Image: {labels_for_hog[i]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Display HOG image\n",
        "    plt.subplot(len(image_paths_for_hog), 2, 2 * i + 2)\n",
        "    plt.imshow(hog_image, cmap=\"gray\")\n",
        "    plt.title(\"HOG Features\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Print feature vector shape\n",
        "    print(f\"Image {i+1} HOG Feature Vector Shape: {features.shape}\")\n",
        "\n",
        "plt.tight_layout()  # Adjust layout to prevent overlapping\n",
        "plt.show()\n",
        "\n",
        "X = np.array(features_list)\n",
        "y = np.array([1 if label == \"with_mask\" else 0 for label in labels_list])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train SVM\n",
        "svm_classifier = SVC(kernel='linear')\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "y_pred_svm = svm_classifier.predict(X_test)\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "print(\"\\nSVM Accuracy:\", accuracy_svm)\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "\n",
        "# Train Random Forest\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "y_pred_rf = rf_classifier.predict(X_test)\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(\"\\nRandom Forest Accuracy:\", accuracy_rf)\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "# Train Neural Network (CNN)\n",
        "model = models.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), verbose=0)\n",
        "\n",
        "# Evaluate Neural Network\n",
        "loss, accuracy_nn = model.evaluate(X_test, y_test)\n",
        "print(f\"\\nNeural Network Accuracy: {accuracy_nn}\")\n",
        "\n",
        "#Generate Classification Report.\n",
        "y_pred_proba_nn = model.predict(X_test)\n",
        "y_pred_nn = (y_pred_proba_nn > 0.5).astype(int)\n",
        "print(classification_report(y_test, y_pred_nn))\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training accuracy', 'Validation accuracy'], loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AW6SyHMWNV9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# ... (Your existing code for loading data, preprocessing, and training the models) ...\n",
        "\n",
        "# Assuming 'model' is your trained neural network model\n",
        "# and 'svm_classifier' is your trained SVM model\n",
        "# and X_test, y_test are already defined.\n",
        "\n",
        "def preprocess_image(image_path, target_size=(50, 50)): # Add target_size\n",
        "    \"\"\"Preprocesses a single image for prediction using HOG features.\"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img_resized = cv2.resize(img, target_size)\n",
        "    features, hog_image = hog(img_resized, pixels_per_cell=(8, 8),\n",
        "                             cells_per_block=(2, 2), visualize=True)\n",
        "    return features.reshape(1, -1)  # Reshape for model prediction\n",
        "\n",
        "def predict_mask(image_path, model_type=\"nn\"):\n",
        "    \"\"\"Predicts if an image has a mask using the specified model.\"\"\"\n",
        "    img_processed = preprocess_image(image_path)\n",
        "\n",
        "    if model_type == \"nn\":\n",
        "        prediction = model.predict(img_processed)\n",
        "        if prediction[0][0] > 0.5:\n",
        "            return \"With Mask\"\n",
        "        else:\n",
        "            return \"Without Mask\"\n",
        "    elif model_type == \"svm\":\n",
        "        prediction = svm_classifier.predict(img_processed)\n",
        "        if prediction[0] == 1:\n",
        "            return \"With Mask\"\n",
        "        else:\n",
        "            return \"Without Mask\"\n",
        "    else:\n",
        "        return \"Invalid model type. Please choose 'nn' or 'svm'.\"\n",
        "\n",
        "# Interactive Prediction Loop\n",
        "while True:\n",
        "    image_path = input(\"Enter the image path (or type 'exit' to quit): \")\n",
        "    if image_path.lower() == \"exit\":\n",
        "        break\n",
        "\n",
        "    model_choice = input(\"Enter 'nn' for neural network or 'svm' for SVM: \").lower()\n",
        "    prediction_result = predict_mask(image_path, model_choice)\n",
        "\n",
        "    print(f\"Prediction: {prediction_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDHHAtnIOqA7",
        "outputId": "1305c77c-21eb-4e05-c518-4c3db989a2b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the image path (or type 'exit' to quit): /content/Face-Mask-Detection/dataset/without_mask/0_0_aidai_0029.jpg\n",
            "Enter 'nn' for neural network or 'svm' for SVM: nn\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "Prediction: Without Mask\n",
            "Enter the image path (or type 'exit' to quit): /content/Face-Mask-Detection/dataset/without_mask/0_0_aidai_0029.jpg\n",
            "Enter 'nn' for neural network or 'svm' for SVM: svm\n",
            "Prediction: Without Mask\n",
            "Enter the image path (or type 'exit' to quit): exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "54m7dZMei2Og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Function to gather image paths and assign labels based on folder names\n",
        "def get_data(dataset_dir, label_map):\n",
        "    data = []\n",
        "    for folder, label in label_map.items():\n",
        "        folder_path = os.path.join(dataset_dir, folder)\n",
        "        for img_file in os.listdir(folder_path):\n",
        "            if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                data.append((os.path.join(folder_path, img_file), label))\n",
        "    return data\n",
        "\n",
        "# Function to split data into train, validation, and test sets\n",
        "def split_data(data, train_ratio=0.7, val_ratio=0.15):\n",
        "    np.random.shuffle(data)\n",
        "    total = len(data)\n",
        "    n_train = int(train_ratio * total)\n",
        "    n_val = int(val_ratio * total)\n",
        "    train_data = data[:n_train]\n",
        "    val_data = data[n_train:n_train+n_val]\n",
        "    test_data = data[n_train+n_val:]\n",
        "    return train_data, val_data, test_data\n",
        "\n",
        "# Custom PyTorch Dataset class\n",
        "class FaceMaskDataset(Dataset):\n",
        "    def __init__(self, data_list, transform=None):\n",
        "        \"\"\"\n",
        "        data_list: List of tuples (image_path, label)\n",
        "        transform: PyTorch transforms to be applied on the image\n",
        "        \"\"\"\n",
        "        self.data_list = data_list\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.data_list[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Specify the dataset directory and label mapping\n",
        "dataset_dir = \"Face-Mask-Detection/dataset\"  # Update this path if necessary\n",
        "label_map = {\"with_mask\": 0, \"without_mask\": 1}\n",
        "\n",
        "# Gather the data and report total count\n",
        "data = get_data(dataset_dir, label_map)\n",
        "print(\"Total images found:\", len(data))\n",
        "\n",
        "# Split data into training, validation, and test sets\n",
        "train_data, val_data, test_data = split_data(data, train_ratio=0.7, val_ratio=0.15)\n",
        "print(\"Train samples:\", len(train_data),\n",
        "      \"Validation samples:\", len(val_data),\n",
        "      \"Test samples:\", len(test_data))\n",
        "\n",
        "# Use the provided mean and std values\n",
        "dataset_mean = [0.5765, 0.4986, 0.4681]\n",
        "dataset_std = [0.2565, 0.2422, 0.2338]\n",
        "\n",
        "# Define final transformation with normalization\n",
        "final_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(dataset_mean, dataset_std)\n",
        "])\n",
        "\n",
        "# Create final datasets using the transformation\n",
        "train_dataset = FaceMaskDataset(train_data, transform=final_transform)\n",
        "val_dataset = FaceMaskDataset(val_data, transform=final_transform)\n",
        "test_dataset = FaceMaskDataset(test_data, transform=final_transform)\n",
        "\n",
        "# Function to create DataLoaders with a given batch_size (modular for hyperparameter tuning)\n",
        "def create_dataloaders(train_dataset, val_dataset, test_dataset, batch_size=32):\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "# Set batch_size as a variable (to be tuned via hyperparameters later)\n",
        "batch_size = 32\n",
        "train_loader, val_loader, test_loader = create_dataloaders(train_dataset, val_dataset, test_dataset, batch_size=batch_size)\n",
        "\n",
        "print(\"DataLoaders are ready for training, validation, and testing.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wt2Amn-vixhC",
        "outputId": "6117daa4-5888-4489-bbdc-368bc8c045d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images found: 4092\n",
            "Train samples: 2864 Validation samples: 613 Test samples: 615\n",
            "DataLoaders are ready for training, validation, and testing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Utility function to return the desired activation module for hidden layers.\n",
        "def get_activation_fn(activation_str):\n",
        "    if activation_str.lower() == \"relu\":\n",
        "        return nn.ReLU(inplace=True)\n",
        "    elif activation_str.lower() == \"leakyrelu\":\n",
        "        return nn.LeakyReLU(inplace=True)\n",
        "    elif activation_str.lower() == \"sigmoid\":\n",
        "        return nn.Sigmoid()  # For hidden layers if desired (though not common)\n",
        "    elif activation_str.lower() == \"tanh\":\n",
        "        return nn.Tanh()\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported activation function: {activation_str}\")\n",
        "\n",
        "# Define a Residual Block with skip connections that accepts a dynamic activation function.\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, activation_str=\"relu\"):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.activation_fn = get_activation_fn(activation_str)\n",
        "        # First convolutional layer\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        # Second convolutional layer\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Downsampling layer if needed to match dimensions for the skip connection\n",
        "        self.downsample = None\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
        "                          stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.activation_fn(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        # Add the skip connection and apply the activation function again.\n",
        "        out += identity\n",
        "        out = self.activation_fn(out)\n",
        "        return out\n",
        "\n",
        "# Define the CNN model with skip connections (a mini ResNet) and modular hyperparameters.\n",
        "# This model uses the chosen activation function (e.g., tanh) for all hidden layers.\n",
        "# The final classification layer does not apply an activation so that during training,\n",
        "# BCEWithLogitsLoss can be used. For inference, you can apply sigmoid externally if needed.\n",
        "class SimpleResNet(nn.Module):\n",
        "    def __init__(self, num_classes=1, base_channels=16, activation_str=\"relu\", num_blocks=[2, 2, 2]):\n",
        "        \"\"\"\n",
        "        num_classes: Number of output classes (use 1 for binary classification)\n",
        "        base_channels: Number of channels in the initial conv layer\n",
        "        activation_str: Activation function to use in hidden layers (e.g., \"relu\", \"leakyrelu\", \"sigmoid\", \"tanh\")\n",
        "        num_blocks: A list defining the number of residual blocks in each layer.\n",
        "                    For example, [2, 2, 2] creates three layers with 2 blocks each.\n",
        "        \"\"\"\n",
        "        super(SimpleResNet, self).__init__()\n",
        "        self.activation_str = activation_str\n",
        "        self.activation_fn = get_activation_fn(activation_str)\n",
        "        self.base_channels = base_channels\n",
        "\n",
        "        # Initial convolutional layer\n",
        "        self.conv = nn.Conv2d(3, base_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(base_channels)\n",
        "\n",
        "        # Create residual layers:\n",
        "        # Layer 1: from base_channels to base_channels\n",
        "        self.layer1 = self._make_layer(ResidualBlock, in_channels=base_channels, out_channels=base_channels,\n",
        "                                       blocks=num_blocks[0], stride=1)\n",
        "        # Layer 2: from base_channels to base_channels * 2\n",
        "        self.layer2 = self._make_layer(ResidualBlock, in_channels=base_channels, out_channels=base_channels*2,\n",
        "                                       blocks=num_blocks[1], stride=2)\n",
        "        # Layer 3: from base_channels * 2 to base_channels * 4\n",
        "        self.layer3 = self._make_layer(ResidualBlock, in_channels=base_channels*2, out_channels=base_channels*4,\n",
        "                                       blocks=num_blocks[2], stride=2)\n",
        "\n",
        "        # Global average pooling and final fully-connected layer.\n",
        "        # Note: We do not apply an activation here so that BCEWithLogitsLoss can be used.\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(base_channels * 4, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, in_channels, out_channels, blocks, stride):\n",
        "        layers = []\n",
        "        # First block with potential downsampling.\n",
        "        layers.append(block(in_channels, out_channels, stride, activation_str=self.activation_str))\n",
        "        # Subsequent blocks.\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(out_channels, out_channels, activation_str=self.activation_str))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initial conv, batch norm, and activation.\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.activation_fn(out)\n",
        "\n",
        "        # Pass through residual layers.\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "\n",
        "        # Global average pooling, flatten, and classification.\n",
        "        out = self.avg_pool(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "# Testing the modified model with a dummy input to ensure it works correctly.\n",
        "if __name__ == \"__main__\":\n",
        "    # For experimentation, you can change the activation_str to \"tanh\".\n",
        "    model = SimpleResNet(num_classes=1, base_channels=16, activation_str=\"tanh\", num_blocks=[2, 2, 2])\n",
        "    dummy_input = torch.randn(1, 3, 256, 256)\n",
        "    output = model(dummy_input)\n",
        "    print(\"Model output shape:\", output.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGtnkPuZjElF",
        "outputId": "f6d458c5-4ec6-47de-a9b7-73553013743b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model output shape: torch.Size([1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "def train(config_defaults):\n",
        "    wandb.init(project=\"face_mask_detection\", config=config_defaults)\n",
        "    config = wandb.config\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    train_loader, val_loader, test_loader = create_dataloaders(train_dataset, val_dataset, test_dataset, batch_size=config.batch_size)\n",
        "\n",
        "    model = SimpleResNet(num_classes=1, base_channels=config.base_channels, activation_str=config.activation_fn, num_blocks=config.num_blocks)\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay) if config.optimizer.lower() == \"adam\" else optim.SGD(model.parameters(), lr=config.learning_rate, momentum=0.9, weight_decay=config.weight_decay)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.1, verbose=True) if config.use_scheduler else None\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    train_losses, val_losses = [], []\n",
        "\n",
        "    for epoch in range(config.epochs):\n",
        "        model.train()\n",
        "        running_train_loss, correct_train, total_train = 0.0, 0, 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.float().unsqueeze(1).to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_train_loss += loss.item() * images.size(0)\n",
        "            preds = (torch.sigmoid(outputs) >= 0.5).float()\n",
        "            correct_train += (preds == labels).sum().item()\n",
        "            total_train += labels.size(0)\n",
        "\n",
        "        train_loss = running_train_loss / len(train_loader.dataset)\n",
        "        train_accuracy = correct_train / total_train\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        model.eval()\n",
        "        running_val_loss, correct_val, total_val = 0.0, 0, 0\n",
        "        correct_class0, total_class0, correct_class1, total_class1 = 0, 0, 0, 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.float().unsqueeze(1).to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                running_val_loss += loss.item() * images.size(0)\n",
        "                preds = (torch.sigmoid(outputs) >= 0.5).float()\n",
        "                correct_val += (preds == labels).sum().item()\n",
        "                total_val += labels.size(0)\n",
        "                mask_class0, mask_class1 = (labels == 0), (labels == 1)\n",
        "                total_class0 += mask_class0.sum().item()\n",
        "                total_class1 += mask_class1.sum().item()\n",
        "                correct_class0 += ((preds == 0) & mask_class0).sum().item()\n",
        "                correct_class1 += ((preds == 1) & mask_class1).sum().item()\n",
        "\n",
        "        val_loss = running_val_loss / len(val_loader.dataset)\n",
        "        val_accuracy = correct_val / total_val\n",
        "        class0_accuracy = correct_class0 / total_class0 if total_class0 > 0 else 0\n",
        "        class1_accuracy = correct_class1 / total_class1 if total_class1 > 0 else 0\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        wandb.log({\"epoch\": epoch, \"train_loss\": train_loss, \"val_loss\": val_loss, \"train_accuracy\": train_accuracy, \"val_accuracy\": val_accuracy, \"val_class0_accuracy\": class0_accuracy, \"val_class1_accuracy\": class1_accuracy})\n",
        "        print(f\"Epoch {epoch+1}/{config.epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), \"best_model.pth\")\n",
        "            print(f\"Saving new best model with validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        if scheduler:\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(train_losses, label=\"Train Loss\")\n",
        "    plt.plot(val_losses, label=\"Validation Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Loss vs Epoch\")\n",
        "    plt.savefig(\"loss_curve.png\")\n",
        "    wandb.log({\"loss_curve\": wandb.Image(\"loss_curve.png\")})\n",
        "    plt.close()\n",
        "\n",
        "    # --- Test Evaluation ---\n",
        "    model.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "    model.eval()\n",
        "    running_test_loss, correct_test, total_test = 0.0, 0, 0\n",
        "    correct_class0, total_class0, correct_class1, total_class1 = 0, 0, 0, 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.float().unsqueeze(1).to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_test_loss += loss.item() * images.size(0)\n",
        "            preds = (torch.sigmoid(outputs) >= 0.5).float()\n",
        "            correct_test += (preds == labels).sum().item()\n",
        "            total_test += labels.size(0)\n",
        "            mask_class0, mask_class1 = (labels == 0), (labels == 1)\n",
        "            total_class0 += mask_class0.sum().item()\n",
        "            total_class1 += mask_class1.sum().item()\n",
        "            correct_class0 += ((preds == 0) & mask_class0).sum().item()\n",
        "            correct_class1 += ((preds == 1) & mask_class1).sum().item()\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    test_loss = running_test_loss / len(test_loader.dataset)\n",
        "    test_accuracy = correct_test / total_test\n",
        "    test_class0_accuracy = correct_class0 / total_class0 if total_class0 > 0 else 0\n",
        "    test_class1_accuracy = correct_class1 / total_class1 if total_class1 > 0 else 0\n",
        "\n",
        "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
        "    print(f\"Test Class 0 Accuracy: {test_class0_accuracy:.4f}, Test Class 1 Accuracy: {test_class1_accuracy:.4f}\")\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(6,6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"No Mask\", \"Mask\"], yticklabels=[\"No Mask\", \"Mask\"])\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.savefig(\"confusion_matrix.png\")\n",
        "    wandb.log({\"confusion_matrix\": wandb.Image(\"confusion_matrix.png\")})\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "60TSa0fN2OQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "config_defaults = {\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"batch_size\": 32,\n",
        "        \"optimizer\": \"adam\",          # Options: \"adam\", \"sgd\", etc.\n",
        "        \"activation_fn\": \"relu\",        # Options: \"relu\", \"leakyrelu\", \"sigmoid\", etc.\n",
        "        \"base_channels\": 16,            # Base number of channels for the model.\n",
        "        \"num_blocks\": [2, 2, 2],        # Number of residual blocks in each layer.\n",
        "        \"epochs\": 20,\n",
        "        \"patience\": 5,                # Early stopping patience.\n",
        "        \"weight_decay\": 1e-4,\n",
        "        \"use_scheduler\": True,        # Whether to use a learning rate scheduler.\n",
        "        # Additional hyperparameters such as dropout rate, kernel size, etc. can be added here.\n",
        "    }\n",
        "train(config_defaults)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "id": "Z-sEJPD5kRmf",
        "outputId": "2ee20281-ddb2-4a27-d287-79975d949663"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msaishruti-prakhya018\u001b[0m (\u001b[33msaishruti-prakhya018-international-institute-of-informat\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250318_060900-rir9riyg</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection/runs/rir9riyg' target=\"_blank\">lunar-microwave-28</a></strong> to <a href='https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection' target=\"_blank\">https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection/runs/rir9riyg' target=\"_blank\">https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection/runs/rir9riyg</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 - Train Loss: 0.4830, Val Loss: 0.5176, Train Acc: 0.7730, Val Acc: 0.7716\n",
            "Saving new best model with validation loss: 0.5176\n",
            "Epoch 2/20 - Train Loss: 0.4397, Val Loss: 0.5339, Train Acc: 0.8059, Val Acc: 0.7602\n",
            "Epoch 3/20 - Train Loss: 0.4377, Val Loss: 0.4857, Train Acc: 0.8027, Val Acc: 0.7896\n",
            "Saving new best model with validation loss: 0.4857\n",
            "Epoch 4/20 - Train Loss: 0.4275, Val Loss: 0.5006, Train Acc: 0.8198, Val Acc: 0.7896\n",
            "Epoch 5/20 - Train Loss: 0.4262, Val Loss: 0.5552, Train Acc: 0.8167, Val Acc: 0.6900\n",
            "Epoch 6/20 - Train Loss: 0.4037, Val Loss: 0.4383, Train Acc: 0.8268, Val Acc: 0.8026\n",
            "Saving new best model with validation loss: 0.4383\n",
            "Epoch 7/20 - Train Loss: 0.3873, Val Loss: 0.5314, Train Acc: 0.8408, Val Acc: 0.7602\n",
            "Epoch 8/20 - Train Loss: 0.3868, Val Loss: 0.5808, Train Acc: 0.8394, Val Acc: 0.7586\n",
            "Epoch 9/20 - Train Loss: 0.3578, Val Loss: 0.3826, Train Acc: 0.8537, Val Acc: 0.8385\n",
            "Saving new best model with validation loss: 0.3826\n",
            "Epoch 10/20 - Train Loss: 0.3447, Val Loss: 0.4113, Train Acc: 0.8624, Val Acc: 0.8108\n",
            "Epoch 11/20 - Train Loss: 0.3161, Val Loss: 0.3412, Train Acc: 0.8767, Val Acc: 0.8711\n",
            "Saving new best model with validation loss: 0.3412\n",
            "Epoch 12/20 - Train Loss: 0.3039, Val Loss: 0.3810, Train Acc: 0.8879, Val Acc: 0.8646\n",
            "Epoch 13/20 - Train Loss: 0.2714, Val Loss: 0.3712, Train Acc: 0.8980, Val Acc: 0.8401\n",
            "Epoch 14/20 - Train Loss: 0.2587, Val Loss: 0.2637, Train Acc: 0.9008, Val Acc: 0.9021\n",
            "Saving new best model with validation loss: 0.2637\n",
            "Epoch 15/20 - Train Loss: 0.2471, Val Loss: 0.2857, Train Acc: 0.9127, Val Acc: 0.8907\n",
            "Epoch 16/20 - Train Loss: 0.2228, Val Loss: 0.4747, Train Acc: 0.9207, Val Acc: 0.8515\n",
            "Epoch 17/20 - Train Loss: 0.2374, Val Loss: 0.4993, Train Acc: 0.9085, Val Acc: 0.7618\n",
            "Epoch 18/20 - Train Loss: 0.2134, Val Loss: 0.3747, Train Acc: 0.9253, Val Acc: 0.8499\n",
            "Epoch 19/20 - Train Loss: 0.1894, Val Loss: 0.1935, Train Acc: 0.9340, Val Acc: 0.9299\n",
            "Saving new best model with validation loss: 0.1935\n",
            "Epoch 20/20 - Train Loss: 0.1679, Val Loss: 0.1915, Train Acc: 0.9459, Val Acc: 0.9266\n",
            "Saving new best model with validation loss: 0.1915\n",
            "Test Loss: 0.1749, Test Accuracy: 0.9301\n",
            "Test Class 0 Accuracy: 0.9527, Test Class 1 Accuracy: 0.9060\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "config_defaults = {\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"batch_size\": 32,\n",
        "        \"optimizer\": \"adam\",          # Options: \"adam\", \"sgd\", etc.\n",
        "        \"activation_fn\": \"leakyrelu\",        # Options: \"relu\", \"leakyrelu\", \"sigmoid\", etc.\n",
        "        \"base_channels\": 16,            # Base number of channels for the model.\n",
        "        \"num_blocks\": [2, 2, 2],        # Number of residual blocks in each layer.\n",
        "        \"epochs\": 50,\n",
        "        \"patience\": 5,                # Early stopping patience.\n",
        "        \"weight_decay\": 1e-4,\n",
        "        \"use_scheduler\": True,        # Whether to use a learning rate scheduler.\n",
        "        # Additional hyperparameters such as dropout rate, kernel size, etc. can be added here.\n",
        "    }\n",
        "train(config_defaults)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dW6U3iFHoOQX",
        "outputId": "6e272f0b-45a5-4a4d-8e10-6b34484bc663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msaishruti-prakhya018\u001b[0m (\u001b[33msaishruti-prakhya018-international-institute-of-informat\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250318_063810-5a1ezvqc</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection/runs/5a1ezvqc' target=\"_blank\">zesty-firebrand-29</a></strong> to <a href='https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection' target=\"_blank\">https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection/runs/5a1ezvqc' target=\"_blank\">https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection/runs/5a1ezvqc</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 - Train Loss: 0.4938, Val Loss: 0.6391, Train Acc: 0.7587, Val Acc: 0.7031\n",
            "Saving new best model with validation loss: 0.6391\n",
            "Epoch 2/50 - Train Loss: 0.4506, Val Loss: 0.6683, Train Acc: 0.7978, Val Acc: 0.7243\n",
            "Epoch 3/50 - Train Loss: 0.4315, Val Loss: 0.6096, Train Acc: 0.8083, Val Acc: 0.7374\n",
            "Saving new best model with validation loss: 0.6096\n",
            "Epoch 4/50 - Train Loss: 0.4331, Val Loss: 0.5227, Train Acc: 0.8142, Val Acc: 0.7716\n",
            "Saving new best model with validation loss: 0.5227\n",
            "Epoch 5/50 - Train Loss: 0.4143, Val Loss: 0.5329, Train Acc: 0.8223, Val Acc: 0.7455\n",
            "Epoch 6/50 - Train Loss: 0.4113, Val Loss: 0.5220, Train Acc: 0.8289, Val Acc: 0.7569\n",
            "Saving new best model with validation loss: 0.5220\n",
            "Epoch 7/50 - Train Loss: 0.3906, Val Loss: 0.4463, Train Acc: 0.8380, Val Acc: 0.8124\n",
            "Saving new best model with validation loss: 0.4463\n",
            "Epoch 8/50 - Train Loss: 0.3651, Val Loss: 0.4659, Train Acc: 0.8499, Val Acc: 0.8026\n",
            "Epoch 9/50 - Train Loss: 0.3519, Val Loss: 0.5356, Train Acc: 0.8586, Val Acc: 0.7390\n",
            "Epoch 10/50 - Train Loss: 0.3326, Val Loss: 0.6678, Train Acc: 0.8656, Val Acc: 0.7227\n",
            "Epoch 11/50 - Train Loss: 0.3036, Val Loss: 0.4239, Train Acc: 0.8788, Val Acc: 0.8532\n",
            "Saving new best model with validation loss: 0.4239\n",
            "Epoch 12/50 - Train Loss: 0.2733, Val Loss: 0.3158, Train Acc: 0.8953, Val Acc: 0.8597\n",
            "Saving new best model with validation loss: 0.3158\n",
            "Epoch 13/50 - Train Loss: 0.2474, Val Loss: 0.3470, Train Acc: 0.9103, Val Acc: 0.8613\n",
            "Epoch 14/50 - Train Loss: 0.2682, Val Loss: 0.3703, Train Acc: 0.8932, Val Acc: 0.8662\n",
            "Epoch 15/50 - Train Loss: 0.2334, Val Loss: 0.2741, Train Acc: 0.9145, Val Acc: 0.8956\n",
            "Saving new best model with validation loss: 0.2741\n",
            "Epoch 16/50 - Train Loss: 0.2017, Val Loss: 0.1969, Train Acc: 0.9288, Val Acc: 0.9266\n",
            "Saving new best model with validation loss: 0.1969\n",
            "Epoch 17/50 - Train Loss: 0.2061, Val Loss: 0.4387, Train Acc: 0.9242, Val Acc: 0.8124\n",
            "Epoch 18/50 - Train Loss: 0.2148, Val Loss: 0.2226, Train Acc: 0.9239, Val Acc: 0.9152\n",
            "Epoch 19/50 - Train Loss: 0.1884, Val Loss: 0.2609, Train Acc: 0.9267, Val Acc: 0.8956\n",
            "Epoch 20/50 - Train Loss: 0.1632, Val Loss: 0.2391, Train Acc: 0.9385, Val Acc: 0.9086\n",
            "Epoch 21/50 - Train Loss: 0.1318, Val Loss: 0.1326, Train Acc: 0.9560, Val Acc: 0.9527\n",
            "Saving new best model with validation loss: 0.1326\n",
            "Epoch 22/50 - Train Loss: 0.1150, Val Loss: 0.1353, Train Acc: 0.9640, Val Acc: 0.9445\n",
            "Epoch 23/50 - Train Loss: 0.1166, Val Loss: 0.1212, Train Acc: 0.9637, Val Acc: 0.9592\n",
            "Saving new best model with validation loss: 0.1212\n",
            "Epoch 24/50 - Train Loss: 0.1085, Val Loss: 0.1271, Train Acc: 0.9658, Val Acc: 0.9576\n",
            "Epoch 25/50 - Train Loss: 0.1060, Val Loss: 0.1222, Train Acc: 0.9672, Val Acc: 0.9625\n",
            "Epoch 26/50 - Train Loss: 0.1028, Val Loss: 0.1209, Train Acc: 0.9679, Val Acc: 0.9625\n",
            "Saving new best model with validation loss: 0.1209\n",
            "Epoch 27/50 - Train Loss: 0.1053, Val Loss: 0.1188, Train Acc: 0.9654, Val Acc: 0.9560\n",
            "Saving new best model with validation loss: 0.1188\n",
            "Epoch 28/50 - Train Loss: 0.1001, Val Loss: 0.1050, Train Acc: 0.9686, Val Acc: 0.9739\n",
            "Saving new best model with validation loss: 0.1050\n",
            "Epoch 29/50 - Train Loss: 0.0964, Val Loss: 0.1052, Train Acc: 0.9710, Val Acc: 0.9674\n",
            "Epoch 30/50 - Train Loss: 0.0911, Val Loss: 0.1026, Train Acc: 0.9738, Val Acc: 0.9723\n",
            "Saving new best model with validation loss: 0.1026\n",
            "Epoch 31/50 - Train Loss: 0.0965, Val Loss: 0.0971, Train Acc: 0.9707, Val Acc: 0.9804\n",
            "Saving new best model with validation loss: 0.0971\n",
            "Epoch 32/50 - Train Loss: 0.0947, Val Loss: 0.1004, Train Acc: 0.9696, Val Acc: 0.9723\n",
            "Epoch 33/50 - Train Loss: 0.0860, Val Loss: 0.0992, Train Acc: 0.9759, Val Acc: 0.9674\n",
            "Epoch 34/50 - Train Loss: 0.0815, Val Loss: 0.0946, Train Acc: 0.9745, Val Acc: 0.9755\n",
            "Saving new best model with validation loss: 0.0946\n",
            "Epoch 35/50 - Train Loss: 0.0827, Val Loss: 0.1077, Train Acc: 0.9756, Val Acc: 0.9625\n",
            "Epoch 36/50 - Train Loss: 0.0804, Val Loss: 0.1077, Train Acc: 0.9801, Val Acc: 0.9690\n",
            "Epoch 37/50 - Train Loss: 0.0821, Val Loss: 0.0977, Train Acc: 0.9759, Val Acc: 0.9723\n",
            "Epoch 38/50 - Train Loss: 0.0756, Val Loss: 0.0972, Train Acc: 0.9787, Val Acc: 0.9690\n",
            "Epoch 39/50 - Train Loss: 0.0740, Val Loss: 0.0903, Train Acc: 0.9797, Val Acc: 0.9739\n",
            "Saving new best model with validation loss: 0.0903\n",
            "Epoch 40/50 - Train Loss: 0.0737, Val Loss: 0.0905, Train Acc: 0.9804, Val Acc: 0.9739\n",
            "Epoch 41/50 - Train Loss: 0.0688, Val Loss: 0.0893, Train Acc: 0.9825, Val Acc: 0.9723\n",
            "Saving new best model with validation loss: 0.0893\n",
            "Epoch 42/50 - Train Loss: 0.0774, Val Loss: 0.0919, Train Acc: 0.9777, Val Acc: 0.9755\n",
            "Epoch 43/50 - Train Loss: 0.0652, Val Loss: 0.0893, Train Acc: 0.9860, Val Acc: 0.9755\n",
            "Saving new best model with validation loss: 0.0893\n",
            "Epoch 44/50 - Train Loss: 0.0682, Val Loss: 0.0876, Train Acc: 0.9829, Val Acc: 0.9755\n",
            "Saving new best model with validation loss: 0.0876\n",
            "Epoch 45/50 - Train Loss: 0.0706, Val Loss: 0.0869, Train Acc: 0.9825, Val Acc: 0.9788\n",
            "Saving new best model with validation loss: 0.0869\n",
            "Epoch 46/50 - Train Loss: 0.0680, Val Loss: 0.0891, Train Acc: 0.9857, Val Acc: 0.9755\n",
            "Epoch 47/50 - Train Loss: 0.0699, Val Loss: 0.0859, Train Acc: 0.9822, Val Acc: 0.9788\n",
            "Saving new best model with validation loss: 0.0859\n",
            "Epoch 48/50 - Train Loss: 0.0693, Val Loss: 0.0882, Train Acc: 0.9857, Val Acc: 0.9723\n",
            "Epoch 49/50 - Train Loss: 0.0761, Val Loss: 0.0894, Train Acc: 0.9808, Val Acc: 0.9739\n",
            "Epoch 50/50 - Train Loss: 0.0738, Val Loss: 0.0910, Train Acc: 0.9797, Val Acc: 0.9723\n",
            "Test Loss: 0.0955, Test Accuracy: 0.9642\n",
            "Test Class 0 Accuracy: 0.9551, Test Class 1 Accuracy: 0.9751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_defaults = {\n",
        "        \"learning_rate\": 0.01,\n",
        "        \"batch_size\": 16,\n",
        "        \"optimizer\": \"sgd\",          # Options: \"adam\", \"sgd\", etc.\n",
        "        \"activation_fn\": \"leakyrelu\",        # Options: \"relu\", \"leakyrelu\", \"sigmoid\", etc.\n",
        "        \"base_channels\": 16,            # Base number of channels for the model.\n",
        "        \"num_blocks\": [2, 2, 2],        # Number of residual blocks in each layer.\n",
        "        \"epochs\": 50,\n",
        "        \"patience\": 5,                # Early stopping patience.\n",
        "        \"weight_decay\": 1e-4,\n",
        "        \"use_scheduler\": False,        # Whether to use a learning rate scheduler.\n",
        "        # Additional hyperparameters such as dropout rate, kernel size, etc. can be added here.\n",
        "    }\n",
        "train(config_defaults)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SnoXDddw_Nr-",
        "outputId": "676383cd-38f0-4594-e16f-4e6f1a98dd3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msaishruti-prakhya018\u001b[0m (\u001b[33msaishruti-prakhya018-international-institute-of-informat\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250318_142544-eri2ysi4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection/runs/eri2ysi4' target=\"_blank\">jumping-brook-31</a></strong> to <a href='https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection' target=\"_blank\">https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection/runs/eri2ysi4' target=\"_blank\">https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection/runs/eri2ysi4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 - Train Loss: 0.5385, Val Loss: 0.6229, Train Acc: 0.7444, Val Acc: 0.7129\n",
            "Saving new best model with validation loss: 0.6229\n",
            "Epoch 2/50 - Train Loss: 0.5083, Val Loss: 0.9287, Train Acc: 0.7685, Val Acc: 0.6917\n",
            "Epoch 3/50 - Train Loss: 0.4923, Val Loss: 0.5636, Train Acc: 0.7699, Val Acc: 0.6868\n",
            "Saving new best model with validation loss: 0.5636\n",
            "Epoch 4/50 - Train Loss: 0.4554, Val Loss: 0.6639, Train Acc: 0.7919, Val Acc: 0.6639\n",
            "Epoch 5/50 - Train Loss: 0.4637, Val Loss: 0.4362, Train Acc: 0.7926, Val Acc: 0.7945\n",
            "Saving new best model with validation loss: 0.4362\n",
            "Epoch 6/50 - Train Loss: 0.4471, Val Loss: 0.4150, Train Acc: 0.8038, Val Acc: 0.7977\n",
            "Saving new best model with validation loss: 0.4150\n",
            "Epoch 7/50 - Train Loss: 0.4173, Val Loss: 0.4148, Train Acc: 0.8251, Val Acc: 0.8157\n",
            "Saving new best model with validation loss: 0.4148\n",
            "Epoch 8/50 - Train Loss: 0.4129, Val Loss: 0.3971, Train Acc: 0.8261, Val Acc: 0.8483\n",
            "Saving new best model with validation loss: 0.3971\n",
            "Epoch 9/50 - Train Loss: 0.4008, Val Loss: 0.3671, Train Acc: 0.8345, Val Acc: 0.8548\n",
            "Saving new best model with validation loss: 0.3671\n",
            "Epoch 10/50 - Train Loss: 0.3722, Val Loss: 0.4914, Train Acc: 0.8467, Val Acc: 0.7667\n",
            "Epoch 11/50 - Train Loss: 0.3619, Val Loss: 0.4404, Train Acc: 0.8506, Val Acc: 0.7912\n",
            "Epoch 12/50 - Train Loss: 0.3363, Val Loss: 0.4537, Train Acc: 0.8628, Val Acc: 0.7993\n",
            "Epoch 13/50 - Train Loss: 0.3127, Val Loss: 0.3311, Train Acc: 0.8778, Val Acc: 0.8597\n",
            "Saving new best model with validation loss: 0.3311\n",
            "Epoch 14/50 - Train Loss: 0.2818, Val Loss: 0.2865, Train Acc: 0.8900, Val Acc: 0.8760\n",
            "Saving new best model with validation loss: 0.2865\n",
            "Epoch 15/50 - Train Loss: 0.2915, Val Loss: 0.3042, Train Acc: 0.8876, Val Acc: 0.8760\n",
            "Epoch 16/50 - Train Loss: 0.2630, Val Loss: 0.4961, Train Acc: 0.8977, Val Acc: 0.8042\n",
            "Epoch 17/50 - Train Loss: 0.2600, Val Loss: 0.2338, Train Acc: 0.8939, Val Acc: 0.9038\n",
            "Saving new best model with validation loss: 0.2338\n",
            "Epoch 18/50 - Train Loss: 0.2391, Val Loss: 0.2183, Train Acc: 0.9043, Val Acc: 0.9070\n",
            "Saving new best model with validation loss: 0.2183\n",
            "Epoch 19/50 - Train Loss: 0.2307, Val Loss: 0.2085, Train Acc: 0.9172, Val Acc: 0.9250\n",
            "Saving new best model with validation loss: 0.2085\n",
            "Epoch 20/50 - Train Loss: 0.2466, Val Loss: 0.2428, Train Acc: 0.9043, Val Acc: 0.8989\n",
            "Epoch 21/50 - Train Loss: 0.2257, Val Loss: 0.2033, Train Acc: 0.9155, Val Acc: 0.9250\n",
            "Saving new best model with validation loss: 0.2033\n",
            "Epoch 22/50 - Train Loss: 0.2323, Val Loss: 0.2903, Train Acc: 0.9103, Val Acc: 0.8858\n",
            "Epoch 23/50 - Train Loss: 0.2094, Val Loss: 0.3994, Train Acc: 0.9190, Val Acc: 0.8385\n",
            "Epoch 24/50 - Train Loss: 0.1905, Val Loss: 0.1868, Train Acc: 0.9291, Val Acc: 0.9299\n",
            "Saving new best model with validation loss: 0.1868\n",
            "Epoch 25/50 - Train Loss: 0.1901, Val Loss: 0.2095, Train Acc: 0.9288, Val Acc: 0.9086\n",
            "Epoch 26/50 - Train Loss: 0.1819, Val Loss: 0.1682, Train Acc: 0.9298, Val Acc: 0.9396\n",
            "Saving new best model with validation loss: 0.1682\n",
            "Epoch 27/50 - Train Loss: 0.1820, Val Loss: 0.1561, Train Acc: 0.9291, Val Acc: 0.9462\n",
            "Saving new best model with validation loss: 0.1561\n",
            "Epoch 28/50 - Train Loss: 0.1446, Val Loss: 0.1884, Train Acc: 0.9466, Val Acc: 0.9347\n",
            "Epoch 29/50 - Train Loss: 0.1672, Val Loss: 0.3806, Train Acc: 0.9378, Val Acc: 0.8450\n",
            "Epoch 30/50 - Train Loss: 0.1636, Val Loss: 0.1758, Train Acc: 0.9385, Val Acc: 0.9282\n",
            "Epoch 31/50 - Train Loss: 0.1607, Val Loss: 0.4142, Train Acc: 0.9354, Val Acc: 0.8157\n",
            "Epoch 32/50 - Train Loss: 0.1602, Val Loss: 0.1471, Train Acc: 0.9385, Val Acc: 0.9429\n",
            "Saving new best model with validation loss: 0.1471\n",
            "Epoch 33/50 - Train Loss: 0.1471, Val Loss: 0.1559, Train Acc: 0.9459, Val Acc: 0.9429\n",
            "Epoch 34/50 - Train Loss: 0.1228, Val Loss: 0.1538, Train Acc: 0.9553, Val Acc: 0.9445\n",
            "Epoch 35/50 - Train Loss: 0.1357, Val Loss: 0.1701, Train Acc: 0.9518, Val Acc: 0.9364\n",
            "Epoch 36/50 - Train Loss: 0.1409, Val Loss: 0.1433, Train Acc: 0.9469, Val Acc: 0.9478\n",
            "Saving new best model with validation loss: 0.1433\n",
            "Epoch 37/50 - Train Loss: 0.1370, Val Loss: 0.1337, Train Acc: 0.9504, Val Acc: 0.9478\n",
            "Saving new best model with validation loss: 0.1337\n",
            "Epoch 38/50 - Train Loss: 0.1185, Val Loss: 0.1547, Train Acc: 0.9543, Val Acc: 0.9462\n",
            "Epoch 39/50 - Train Loss: 0.1245, Val Loss: 0.2568, Train Acc: 0.9588, Val Acc: 0.9135\n",
            "Epoch 40/50 - Train Loss: 0.1103, Val Loss: 0.1302, Train Acc: 0.9598, Val Acc: 0.9527\n",
            "Saving new best model with validation loss: 0.1302\n",
            "Epoch 41/50 - Train Loss: 0.1368, Val Loss: 0.1861, Train Acc: 0.9497, Val Acc: 0.9299\n",
            "Epoch 42/50 - Train Loss: 0.1026, Val Loss: 0.1130, Train Acc: 0.9633, Val Acc: 0.9608\n",
            "Saving new best model with validation loss: 0.1130\n",
            "Epoch 43/50 - Train Loss: 0.1078, Val Loss: 0.1223, Train Acc: 0.9598, Val Acc: 0.9608\n",
            "Epoch 44/50 - Train Loss: 0.1233, Val Loss: 0.1421, Train Acc: 0.9522, Val Acc: 0.9462\n",
            "Epoch 45/50 - Train Loss: 0.1043, Val Loss: 0.1034, Train Acc: 0.9588, Val Acc: 0.9657\n",
            "Saving new best model with validation loss: 0.1034\n",
            "Epoch 46/50 - Train Loss: 0.0847, Val Loss: 0.1285, Train Acc: 0.9710, Val Acc: 0.9543\n",
            "Epoch 47/50 - Train Loss: 0.0996, Val Loss: 0.1682, Train Acc: 0.9612, Val Acc: 0.9396\n",
            "Epoch 48/50 - Train Loss: 0.0911, Val Loss: 0.1550, Train Acc: 0.9668, Val Acc: 0.9429\n",
            "Epoch 49/50 - Train Loss: 0.0944, Val Loss: 0.1700, Train Acc: 0.9665, Val Acc: 0.9445\n",
            "Epoch 50/50 - Train Loss: 0.1092, Val Loss: 0.1456, Train Acc: 0.9581, Val Acc: 0.9445\n",
            "Test Loss: 0.0749, Test Accuracy: 0.9724\n",
            "Test Class 0 Accuracy: 0.9591, Test Class 1 Accuracy: 0.9865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_defaults = {\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"batch_size\": 16,\n",
        "        \"optimizer\": \"adam\",          # Options: \"adam\", \"sgd\", etc.\n",
        "        \"activation_fn\": \"sigmoid\",        # Options: \"relu\", \"leakyrelu\", \"sigmoid\", etc.\n",
        "        \"base_channels\": 16,            # Base number of channels for the model.\n",
        "        \"num_blocks\": [2, 2, 2],        # Number of residual blocks in each layer.\n",
        "        \"epochs\": 50,\n",
        "        \"patience\": 5,                # Early stopping patience.\n",
        "        \"weight_decay\": 1e-4,\n",
        "        \"use_scheduler\": False,        # Whether to use a learning rate scheduler.\n",
        "        # Additional hyperparameters such as dropout rate, kernel size, etc. can be added here.\n",
        "    }\n",
        "train(config_defaults)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "id": "H14XpO8cD3is",
        "outputId": "bd953d09-31e3-4cd4-b471-7d73f381baff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msaishruti-prakhya018\u001b[0m (\u001b[33msaishruti-prakhya018-international-institute-of-informat\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250319_032749-guxs6kkp</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection/runs/guxs6kkp' target=\"_blank\">wobbly-plasma-33</a></strong> to <a href='https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection' target=\"_blank\">https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection/runs/guxs6kkp' target=\"_blank\">https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection/runs/guxs6kkp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-19879950f6db>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Additional hyperparameters such as dropout rate, kernel size, etc. can be added here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     }\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-547e55c41735>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config_defaults)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mrunning_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mcorrect_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_defaults = {\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"batch_size\": 32,\n",
        "        \"optimizer\": \"adam\",          # Options: \"adam\", \"sgd\", etc.\n",
        "        \"activation_fn\": \"tanh\",        # Options: \"relu\", \"leakyrelu\", \"sigmoid\", etc.\n",
        "        \"base_channels\": 16,            # Base number of channels for the model.\n",
        "        \"num_blocks\": [2, 2, 2],        # Number of residual blocks in each layer.\n",
        "        \"epochs\": 50,\n",
        "        \"patience\": 5,                # Early stopping patience.\n",
        "        \"weight_decay\": 1e-4,\n",
        "        \"use_scheduler\": True,        # Whether to use a learning rate scheduler.\n",
        "        # Additional hyperparameters such as dropout rate, kernel size, etc. can be added here.\n",
        "    }\n",
        "train(config_defaults)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o-crB_xEMvRH",
        "outputId": "d89d1c40-ba71-4696-de75-f35191b1ca8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msaishruti-prakhya018\u001b[0m (\u001b[33msaishruti-prakhya018-international-institute-of-informat\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250319_033023-30e7zgpq</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection/runs/30e7zgpq' target=\"_blank\">crimson-vortex-34</a></strong> to <a href='https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection' target=\"_blank\">https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection/runs/30e7zgpq' target=\"_blank\">https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection/runs/30e7zgpq</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 - Train Loss: 0.5131, Val Loss: 0.5462, Train Acc: 0.7483, Val Acc: 0.7602\n",
            "Saving new best model with validation loss: 0.5462\n",
            "Epoch 2/50 - Train Loss: 0.4941, Val Loss: 0.5599, Train Acc: 0.7689, Val Acc: 0.7455\n",
            "Epoch 3/50 - Train Loss: 0.4700, Val Loss: 0.4669, Train Acc: 0.7807, Val Acc: 0.7749\n",
            "Saving new best model with validation loss: 0.4669\n",
            "Epoch 4/50 - Train Loss: 0.4653, Val Loss: 0.4198, Train Acc: 0.7909, Val Acc: 0.8140\n",
            "Saving new best model with validation loss: 0.4198\n",
            "Epoch 5/50 - Train Loss: 0.4468, Val Loss: 0.4154, Train Acc: 0.7950, Val Acc: 0.8352\n",
            "Saving new best model with validation loss: 0.4154\n",
            "Epoch 6/50 - Train Loss: 0.4428, Val Loss: 0.5486, Train Acc: 0.8083, Val Acc: 0.7390\n",
            "Epoch 7/50 - Train Loss: 0.4493, Val Loss: 0.4445, Train Acc: 0.7968, Val Acc: 0.8108\n",
            "Epoch 8/50 - Train Loss: 0.4248, Val Loss: 0.5297, Train Acc: 0.8167, Val Acc: 0.7080\n",
            "Epoch 9/50 - Train Loss: 0.3976, Val Loss: 0.8979, Train Acc: 0.8373, Val Acc: 0.5041\n",
            "Epoch 10/50 - Train Loss: 0.3798, Val Loss: 0.3575, Train Acc: 0.8478, Val Acc: 0.8728\n",
            "Saving new best model with validation loss: 0.3575\n",
            "Epoch 11/50 - Train Loss: 0.3678, Val Loss: 0.3522, Train Acc: 0.8579, Val Acc: 0.8630\n",
            "Saving new best model with validation loss: 0.3522\n",
            "Epoch 12/50 - Train Loss: 0.3604, Val Loss: 0.3451, Train Acc: 0.8624, Val Acc: 0.8695\n",
            "Saving new best model with validation loss: 0.3451\n",
            "Epoch 13/50 - Train Loss: 0.3520, Val Loss: 0.3455, Train Acc: 0.8708, Val Acc: 0.8711\n",
            "Epoch 14/50 - Train Loss: 0.3554, Val Loss: 0.3534, Train Acc: 0.8635, Val Acc: 0.8728\n",
            "Epoch 15/50 - Train Loss: 0.3374, Val Loss: 0.3322, Train Acc: 0.8736, Val Acc: 0.8793\n",
            "Saving new best model with validation loss: 0.3322\n",
            "Epoch 16/50 - Train Loss: 0.3449, Val Loss: 0.3733, Train Acc: 0.8715, Val Acc: 0.8581\n",
            "Epoch 17/50 - Train Loss: 0.3372, Val Loss: 0.3184, Train Acc: 0.8726, Val Acc: 0.8874\n",
            "Saving new best model with validation loss: 0.3184\n",
            "Epoch 18/50 - Train Loss: 0.3254, Val Loss: 0.3257, Train Acc: 0.8771, Val Acc: 0.8777\n",
            "Epoch 19/50 - Train Loss: 0.3207, Val Loss: 0.3699, Train Acc: 0.8806, Val Acc: 0.8515\n",
            "Epoch 20/50 - Train Loss: 0.3228, Val Loss: 0.3217, Train Acc: 0.8726, Val Acc: 0.8809\n",
            "Epoch 21/50 - Train Loss: 0.3020, Val Loss: 0.4486, Train Acc: 0.8893, Val Acc: 0.7879\n",
            "Epoch 22/50 - Train Loss: 0.2993, Val Loss: 0.2921, Train Acc: 0.8837, Val Acc: 0.8956\n",
            "Saving new best model with validation loss: 0.2921\n",
            "Epoch 23/50 - Train Loss: 0.2986, Val Loss: 0.2871, Train Acc: 0.8883, Val Acc: 0.8956\n",
            "Saving new best model with validation loss: 0.2871\n",
            "Epoch 24/50 - Train Loss: 0.2939, Val Loss: 0.2857, Train Acc: 0.8893, Val Acc: 0.8989\n",
            "Saving new best model with validation loss: 0.2857\n",
            "Epoch 25/50 - Train Loss: 0.2967, Val Loss: 0.2823, Train Acc: 0.8890, Val Acc: 0.8956\n",
            "Saving new best model with validation loss: 0.2823\n",
            "Epoch 26/50 - Train Loss: 0.2994, Val Loss: 0.2853, Train Acc: 0.8858, Val Acc: 0.9054\n",
            "Epoch 27/50 - Train Loss: 0.2932, Val Loss: 0.2871, Train Acc: 0.8914, Val Acc: 0.9038\n",
            "Epoch 28/50 - Train Loss: 0.2962, Val Loss: 0.2862, Train Acc: 0.8918, Val Acc: 0.9005\n",
            "Epoch 29/50 - Train Loss: 0.2946, Val Loss: 0.2869, Train Acc: 0.8953, Val Acc: 0.8989\n",
            "Epoch 30/50 - Train Loss: 0.2903, Val Loss: 0.2831, Train Acc: 0.8946, Val Acc: 0.9054\n",
            "Epoch 31/50 - Train Loss: 0.2906, Val Loss: 0.2889, Train Acc: 0.8977, Val Acc: 0.9021\n",
            "Epoch 32/50 - Train Loss: 0.2862, Val Loss: 0.2875, Train Acc: 0.8907, Val Acc: 0.9005\n",
            "Epoch 33/50 - Train Loss: 0.2901, Val Loss: 0.2813, Train Acc: 0.8914, Val Acc: 0.8972\n",
            "Saving new best model with validation loss: 0.2813\n",
            "Epoch 34/50 - Train Loss: 0.2968, Val Loss: 0.2839, Train Acc: 0.8869, Val Acc: 0.9038\n",
            "Epoch 35/50 - Train Loss: 0.2882, Val Loss: 0.2871, Train Acc: 0.8911, Val Acc: 0.8989\n",
            "Epoch 36/50 - Train Loss: 0.2844, Val Loss: 0.2841, Train Acc: 0.8966, Val Acc: 0.9070\n",
            "Epoch 37/50 - Train Loss: 0.2904, Val Loss: 0.2817, Train Acc: 0.8942, Val Acc: 0.9005\n",
            "Epoch 38/50 - Train Loss: 0.2942, Val Loss: 0.2822, Train Acc: 0.8900, Val Acc: 0.9005\n",
            "Epoch 39/50 - Train Loss: 0.2870, Val Loss: 0.2813, Train Acc: 0.8907, Val Acc: 0.9054\n",
            "Epoch 40/50 - Train Loss: 0.2901, Val Loss: 0.2805, Train Acc: 0.8949, Val Acc: 0.9021\n",
            "Saving new best model with validation loss: 0.2805\n",
            "Epoch 41/50 - Train Loss: 0.2761, Val Loss: 0.2790, Train Acc: 0.9005, Val Acc: 0.8989\n",
            "Saving new best model with validation loss: 0.2790\n",
            "Epoch 42/50 - Train Loss: 0.2920, Val Loss: 0.2860, Train Acc: 0.8921, Val Acc: 0.9021\n",
            "Epoch 43/50 - Train Loss: 0.2837, Val Loss: 0.2817, Train Acc: 0.8959, Val Acc: 0.9021\n",
            "Epoch 44/50 - Train Loss: 0.2845, Val Loss: 0.2809, Train Acc: 0.8959, Val Acc: 0.8956\n",
            "Epoch 45/50 - Train Loss: 0.2829, Val Loss: 0.2818, Train Acc: 0.8970, Val Acc: 0.9054\n",
            "Epoch 46/50 - Train Loss: 0.2865, Val Loss: 0.2856, Train Acc: 0.8973, Val Acc: 0.9070\n",
            "Epoch 47/50 - Train Loss: 0.2882, Val Loss: 0.2817, Train Acc: 0.8914, Val Acc: 0.9070\n",
            "Epoch 48/50 - Train Loss: 0.2881, Val Loss: 0.2827, Train Acc: 0.8900, Val Acc: 0.9005\n",
            "Epoch 49/50 - Train Loss: 0.2899, Val Loss: 0.2799, Train Acc: 0.8893, Val Acc: 0.8989\n",
            "Epoch 50/50 - Train Loss: 0.2873, Val Loss: 0.2806, Train Acc: 0.8953, Val Acc: 0.9038\n",
            "Test Loss: 0.2994, Test Accuracy: 0.8862\n",
            "Test Class 0 Accuracy: 0.8914, Test Class 1 Accuracy: 0.8810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_defaults = {\n",
        "        \"learning_rate\": 0.01,\n",
        "        \"batch_size\": 32,\n",
        "        \"optimizer\": \"sgd\",          # Options: \"adam\", \"sgd\", etc.\n",
        "        \"activation_fn\": \"tanh\",        # Options: \"relu\", \"leakyrelu\", \"sigmoid\", etc.\n",
        "        \"base_channels\": 16,            # Base number of channels for the model.\n",
        "        \"num_blocks\": [2, 2, 2],        # Number of residual blocks in each layer.\n",
        "        \"epochs\": 50,\n",
        "        \"patience\": 5,                # Early stopping patience.\n",
        "        \"weight_decay\": 1e-4,\n",
        "        \"use_scheduler\": True,        # Whether to use a learning rate scheduler.\n",
        "        # Additional hyperparameters such as dropout rate, kernel size, etc. can be added here.\n",
        "    }\n",
        "train(config_defaults)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Mz_Yy-QWNWz5",
        "outputId": "46c7ada4-36f5-4da6-e84d-ccb293cd575a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msaishruti-prakhya018\u001b[0m (\u001b[33msaishruti-prakhya018-international-institute-of-informat\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250319_040708-3jx1yi21</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection/runs/3jx1yi21' target=\"_blank\">comic-serenity-35</a></strong> to <a href='https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection' target=\"_blank\">https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection/runs/3jx1yi21' target=\"_blank\">https://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection/runs/3jx1yi21</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 - Train Loss: 0.5414, Val Loss: 0.6291, Train Acc: 0.7469, Val Acc: 0.6966\n",
            "Saving new best model with validation loss: 0.6291\n",
            "Epoch 2/50 - Train Loss: 0.5095, Val Loss: 0.7086, Train Acc: 0.7622, Val Acc: 0.6297\n",
            "Epoch 3/50 - Train Loss: 0.5050, Val Loss: 0.4336, Train Acc: 0.7563, Val Acc: 0.7961\n",
            "Saving new best model with validation loss: 0.4336\n",
            "Epoch 4/50 - Train Loss: 0.4868, Val Loss: 0.4800, Train Acc: 0.7825, Val Acc: 0.7716\n",
            "Epoch 5/50 - Train Loss: 0.4912, Val Loss: 0.4203, Train Acc: 0.7772, Val Acc: 0.8108\n",
            "Saving new best model with validation loss: 0.4203\n",
            "Epoch 6/50 - Train Loss: 0.4801, Val Loss: 0.4727, Train Acc: 0.7867, Val Acc: 0.7765\n",
            "Epoch 7/50 - Train Loss: 0.4868, Val Loss: 0.4318, Train Acc: 0.7818, Val Acc: 0.8091\n",
            "Epoch 8/50 - Train Loss: 0.4573, Val Loss: 0.4975, Train Acc: 0.8097, Val Acc: 0.7569\n",
            "Epoch 9/50 - Train Loss: 0.4586, Val Loss: 0.5024, Train Acc: 0.7874, Val Acc: 0.7684\n",
            "Epoch 10/50 - Train Loss: 0.4198, Val Loss: 0.3720, Train Acc: 0.8244, Val Acc: 0.8564\n",
            "Saving new best model with validation loss: 0.3720\n",
            "Epoch 11/50 - Train Loss: 0.4157, Val Loss: 0.3443, Train Acc: 0.8324, Val Acc: 0.8777\n",
            "Saving new best model with validation loss: 0.3443\n",
            "Epoch 12/50 - Train Loss: 0.3963, Val Loss: 0.4711, Train Acc: 0.8348, Val Acc: 0.7977\n",
            "Epoch 13/50 - Train Loss: 0.3799, Val Loss: 0.3541, Train Acc: 0.8439, Val Acc: 0.8597\n",
            "Epoch 14/50 - Train Loss: 0.3835, Val Loss: 0.5142, Train Acc: 0.8404, Val Acc: 0.7569\n",
            "Epoch 15/50 - Train Loss: 0.3823, Val Loss: 0.3117, Train Acc: 0.8464, Val Acc: 0.8858\n",
            "Saving new best model with validation loss: 0.3117\n",
            "Epoch 16/50 - Train Loss: 0.3592, Val Loss: 0.3452, Train Acc: 0.8561, Val Acc: 0.8597\n",
            "Epoch 17/50 - Train Loss: 0.3544, Val Loss: 0.4315, Train Acc: 0.8589, Val Acc: 0.8059\n",
            "Epoch 18/50 - Train Loss: 0.3566, Val Loss: 0.3654, Train Acc: 0.8547, Val Acc: 0.8548\n",
            "Epoch 19/50 - Train Loss: 0.3609, Val Loss: 0.3285, Train Acc: 0.8506, Val Acc: 0.8662\n",
            "Epoch 20/50 - Train Loss: 0.3351, Val Loss: 0.2714, Train Acc: 0.8684, Val Acc: 0.8972\n",
            "Saving new best model with validation loss: 0.2714\n",
            "Epoch 21/50 - Train Loss: 0.3260, Val Loss: 0.2702, Train Acc: 0.8792, Val Acc: 0.8989\n",
            "Saving new best model with validation loss: 0.2702\n",
            "Epoch 22/50 - Train Loss: 0.3278, Val Loss: 0.2724, Train Acc: 0.8757, Val Acc: 0.9054\n",
            "Epoch 23/50 - Train Loss: 0.3244, Val Loss: 0.2620, Train Acc: 0.8820, Val Acc: 0.9086\n",
            "Saving new best model with validation loss: 0.2620\n",
            "Epoch 24/50 - Train Loss: 0.3220, Val Loss: 0.2645, Train Acc: 0.8750, Val Acc: 0.9070\n",
            "Epoch 25/50 - Train Loss: 0.3180, Val Loss: 0.2625, Train Acc: 0.8820, Val Acc: 0.9021\n",
            "Epoch 26/50 - Train Loss: 0.3159, Val Loss: 0.2659, Train Acc: 0.8813, Val Acc: 0.9070\n",
            "Epoch 27/50 - Train Loss: 0.3190, Val Loss: 0.2590, Train Acc: 0.8771, Val Acc: 0.9054\n",
            "Saving new best model with validation loss: 0.2590\n",
            "Epoch 28/50 - Train Loss: 0.3074, Val Loss: 0.2630, Train Acc: 0.8872, Val Acc: 0.9201\n",
            "Epoch 29/50 - Train Loss: 0.3196, Val Loss: 0.3059, Train Acc: 0.8813, Val Acc: 0.9086\n",
            "Epoch 30/50 - Train Loss: 0.3088, Val Loss: 0.2594, Train Acc: 0.8799, Val Acc: 0.9086\n",
            "Epoch 31/50 - Train Loss: 0.3138, Val Loss: 0.2536, Train Acc: 0.8837, Val Acc: 0.9103\n",
            "Saving new best model with validation loss: 0.2536\n",
            "Epoch 32/50 - Train Loss: 0.3098, Val Loss: 0.2899, Train Acc: 0.8823, Val Acc: 0.9201\n",
            "Epoch 33/50 - Train Loss: 0.3125, Val Loss: 0.2678, Train Acc: 0.8823, Val Acc: 0.9233\n",
            "Epoch 34/50 - Train Loss: 0.3027, Val Loss: 0.2569, Train Acc: 0.8914, Val Acc: 0.9152\n",
            "Epoch 35/50 - Train Loss: 0.3143, Val Loss: 0.2606, Train Acc: 0.8781, Val Acc: 0.9201\n",
            "Epoch 36/50 - Train Loss: 0.3051, Val Loss: 0.2613, Train Acc: 0.8827, Val Acc: 0.9119\n",
            "Epoch 37/50 - Train Loss: 0.3049, Val Loss: 0.2568, Train Acc: 0.8890, Val Acc: 0.9152\n",
            "Epoch 38/50 - Train Loss: 0.2986, Val Loss: 0.2527, Train Acc: 0.8893, Val Acc: 0.9201\n",
            "Saving new best model with validation loss: 0.2527\n",
            "Epoch 39/50 - Train Loss: 0.3070, Val Loss: 0.2595, Train Acc: 0.8897, Val Acc: 0.9184\n",
            "Epoch 40/50 - Train Loss: 0.3035, Val Loss: 0.2601, Train Acc: 0.8827, Val Acc: 0.9168\n",
            "Epoch 41/50 - Train Loss: 0.3041, Val Loss: 0.2519, Train Acc: 0.8834, Val Acc: 0.9184\n",
            "Saving new best model with validation loss: 0.2519\n",
            "Epoch 42/50 - Train Loss: 0.3071, Val Loss: 0.2542, Train Acc: 0.8897, Val Acc: 0.9168\n",
            "Epoch 43/50 - Train Loss: 0.3033, Val Loss: 0.2532, Train Acc: 0.8862, Val Acc: 0.9168\n",
            "Epoch 44/50 - Train Loss: 0.3029, Val Loss: 0.2497, Train Acc: 0.8862, Val Acc: 0.9103\n",
            "Saving new best model with validation loss: 0.2497\n",
            "Epoch 45/50 - Train Loss: 0.3013, Val Loss: 0.2551, Train Acc: 0.8886, Val Acc: 0.9119\n",
            "Epoch 46/50 - Train Loss: 0.3012, Val Loss: 0.2643, Train Acc: 0.8872, Val Acc: 0.9201\n",
            "Epoch 47/50 - Train Loss: 0.2992, Val Loss: 0.2521, Train Acc: 0.8911, Val Acc: 0.9201\n",
            "Epoch 48/50 - Train Loss: 0.3035, Val Loss: 0.2544, Train Acc: 0.8914, Val Acc: 0.9168\n",
            "Epoch 49/50 - Train Loss: 0.2995, Val Loss: 0.2502, Train Acc: 0.8890, Val Acc: 0.9217\n",
            "Epoch 50/50 - Train Loss: 0.3065, Val Loss: 0.2536, Train Acc: 0.8855, Val Acc: 0.9201\n",
            "Test Loss: 0.2959, Test Accuracy: 0.8911\n",
            "Test Class 0 Accuracy: 0.9255, Test Class 1 Accuracy: 0.8532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb sweep sweep_config.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkT_EvqPfiTW",
        "outputId": "9344ba9f-8757-442a-e214-d9e96b568d82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Login to W&B to use the sweep feature\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msaishruti-prakhya018\u001b[0m (\u001b[33msaishruti-prakhya018-international-institute-of-informat\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Creating sweep from: sweep_config.yaml\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Creating sweep with ID: \u001b[33m46lu8sek\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: View sweep at: \u001b[34m\u001b[4mhttps://wandb.ai/saishruti-prakhya018-international-institute-of-informat/face_mask_detection/sweeps/46lu8sek\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run sweep agent with: \u001b[33mwandb agent saishruti-prakhya018-international-institute-of-informat/face_mask_detection/46lu8sek\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb agent --count 10 saishruti-prakhya018-international-institute-of-informat/face_mask_detection/46lu8sek"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KjjXYKyfy3i",
        "outputId": "da6a7af4-6bcd-406b-c918-125494475b2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent \n",
            "2025-03-17 10:05:39,442 - wandb.wandb_agent - INFO - Running runs: []\n",
            "2025-03-17 10:05:39,783 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2025-03-17 10:05:39,784 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tactivation_fn: leakyrelu\n",
            "\tbase_channels: 32\n",
            "\tbatch_size: 16\n",
            "\tepochs: 30\n",
            "\tlearning_rate: 0.007252211589517256\n",
            "\toptimizer: adam\n",
            "\tpatience: 5\n",
            "\tuse_scheduler: True\n",
            "\tweight_decay: 0.00019733677006572895\n",
            "2025-03-17 10:05:39,785 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --activation_fn=leakyrelu --base_channels=32 --batch_size=16 --epochs=30 --learning_rate=0.007252211589517256 --optimizer=adam --patience=5 --use_scheduler=True --weight_decay=0.00019733677006572895\n",
            "fatal: destination path 'Face-Mask-Detection' already exists and is not an empty directory.\n",
            "Dataset directories: ['without_mask', 'with_mask']\n",
            "<PIL.Image.Image image mode=RGB size=159x242 at 0x7EB6377F9410>\n",
            "Label for 'with_mask': 0\n",
            "Total images found: 4092\n",
            "Train samples: 2864 Validation samples: 613 Test samples: 615\n",
            "DataLoaders are ready for training, validation, and testing.\n",
            "2025-03-17 10:05:44,797 - wandb.wandb_agent - INFO - Running runs: ['qvr6stsi']\n",
            "2025-03-17 10:05:49,875 - wandb.wandb_agent - INFO - Cleaning up finished run: qvr6stsi\n",
            "2025-03-17 10:05:50,495 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2025-03-17 10:05:50,495 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tactivation_fn: relu\n",
            "\tbase_channels: 16\n",
            "\tbatch_size: 32\n",
            "\tepochs: 30\n",
            "\tlearning_rate: 0.00945376108428774\n",
            "\toptimizer: adam\n",
            "\tpatience: 5\n",
            "\tuse_scheduler: True\n",
            "\tweight_decay: 0.0007728084773252127\n",
            "2025-03-17 10:05:50,497 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --activation_fn=relu --base_channels=16 --batch_size=32 --epochs=30 --learning_rate=0.00945376108428774 --optimizer=adam --patience=5 --use_scheduler=True --weight_decay=0.0007728084773252127\n",
            "fatal: destination path 'Face-Mask-Detection' already exists and is not an empty directory.\n",
            "Dataset directories: ['without_mask', 'with_mask']\n",
            "<PIL.Image.Image image mode=RGB size=159x242 at 0x7BB40BB8F850>\n",
            "Label for 'with_mask': 0\n",
            "Total images found: 4092\n",
            "Train samples: 2864 Validation samples: 613 Test samples: 615\n",
            "DataLoaders are ready for training, validation, and testing.\n",
            "2025-03-17 10:05:55,508 - wandb.wandb_agent - INFO - Running runs: ['qzck6w5w']\n",
            "2025-03-17 10:06:00,572 - wandb.wandb_agent - INFO - Cleaning up finished run: qzck6w5w\n",
            "2025-03-17 10:06:00,807 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2025-03-17 10:06:00,807 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tactivation_fn: relu\n",
            "\tbase_channels: 32\n",
            "\tbatch_size: 64\n",
            "\tepochs: 30\n",
            "\tlearning_rate: 0.00786125959269972\n",
            "\toptimizer: sgd\n",
            "\tpatience: 5\n",
            "\tuse_scheduler: True\n",
            "\tweight_decay: 0.0005786858578585825\n",
            "2025-03-17 10:06:00,808 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --activation_fn=relu --base_channels=32 --batch_size=64 --epochs=30 --learning_rate=0.00786125959269972 --optimizer=sgd --patience=5 --use_scheduler=True --weight_decay=0.0005786858578585825\n",
            "fatal: destination path 'Face-Mask-Detection' already exists and is not an empty directory.\n",
            "Dataset directories: ['without_mask', 'with_mask']\n",
            "<PIL.Image.Image image mode=RGB size=159x242 at 0x7DB8E781F990>\n",
            "Label for 'with_mask': 0\n",
            "Total images found: 4092\n",
            "Train samples: 2864 Validation samples: 613 Test samples: 615\n",
            "DataLoaders are ready for training, validation, and testing.\n",
            "2025-03-17 10:06:05,819 - wandb.wandb_agent - INFO - Running runs: ['7b61ljzl']\n",
            "2025-03-17 10:06:10,883 - wandb.wandb_agent - INFO - Cleaning up finished run: 7b61ljzl\n",
            "2025-03-17 10:06:11,084 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2025-03-17 10:06:11,084 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tactivation_fn: tanh\n",
            "\tbase_channels: 16\n",
            "\tbatch_size: 16\n",
            "\tepochs: 30\n",
            "\tlearning_rate: 0.006456135735193539\n",
            "\toptimizer: sgd\n",
            "\tpatience: 5\n",
            "\tuse_scheduler: True\n",
            "\tweight_decay: 0.000952081218599146\n",
            "2025-03-17 10:06:11,086 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --activation_fn=tanh --base_channels=16 --batch_size=16 --epochs=30 --learning_rate=0.006456135735193539 --optimizer=sgd --patience=5 --use_scheduler=True --weight_decay=0.000952081218599146\n",
            "fatal: destination path 'Face-Mask-Detection' already exists and is not an empty directory.\n",
            "Dataset directories: ['without_mask', 'with_mask']\n",
            "<PIL.Image.Image image mode=RGB size=159x242 at 0x7BACE6EB60D0>\n",
            "Label for 'with_mask': 0\n",
            "Total images found: 4092\n",
            "Train samples: 2864 Validation samples: 613 Test samples: 615\n",
            "DataLoaders are ready for training, validation, and testing.\n",
            "2025-03-17 10:06:16,097 - wandb.wandb_agent - INFO - Running runs: ['43kad2yo']\n",
            "2025-03-17 10:06:16,097 - wandb.wandb_agent - INFO - Cleaning up finished run: 43kad2yo\n",
            "2025-03-17 10:06:16,446 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2025-03-17 10:06:16,446 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tactivation_fn: relu\n",
            "\tbase_channels: 32\n",
            "\tbatch_size: 64\n",
            "\tepochs: 30\n",
            "\tlearning_rate: 0.004410177995568001\n",
            "\toptimizer: adam\n",
            "\tpatience: 5\n",
            "\tuse_scheduler: True\n",
            "\tweight_decay: 0.00093965834197824\n",
            "2025-03-17 10:06:16,447 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --activation_fn=relu --base_channels=32 --batch_size=64 --epochs=30 --learning_rate=0.004410177995568001 --optimizer=adam --patience=5 --use_scheduler=True --weight_decay=0.00093965834197824\n",
            "fatal: destination path 'Face-Mask-Detection' already exists and is not an empty directory.\n",
            "Dataset directories: ['without_mask', 'with_mask']\n",
            "<PIL.Image.Image image mode=RGB size=159x242 at 0x7F00DBC81590>\n",
            "Label for 'with_mask': 0\n",
            "Total images found: 4092\n",
            "Train samples: 2864 Validation samples: 613 Test samples: 615\n",
            "DataLoaders are ready for training, validation, and testing.\n",
            "2025-03-17 10:06:21,460 - wandb.wandb_agent - INFO - Running runs: ['0rk0y7w5']\n",
            "2025-03-17 10:06:26,533 - wandb.wandb_agent - INFO - Cleaning up finished run: 0rk0y7w5\n",
            "2025-03-17 10:06:26,715 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2025-03-17 10:06:26,715 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tactivation_fn: leakyrelu\n",
            "\tbase_channels: 16\n",
            "\tbatch_size: 64\n",
            "\tepochs: 30\n",
            "\tlearning_rate: 0.003285043856853656\n",
            "\toptimizer: adam\n",
            "\tpatience: 5\n",
            "\tuse_scheduler: True\n",
            "\tweight_decay: 8.06185152149075e-05\n",
            "2025-03-17 10:06:26,717 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --activation_fn=leakyrelu --base_channels=16 --batch_size=64 --epochs=30 --learning_rate=0.003285043856853656 --optimizer=adam --patience=5 --use_scheduler=True --weight_decay=8.06185152149075e-05\n",
            "fatal: destination path 'Face-Mask-Detection' already exists and is not an empty directory.\n",
            "Dataset directories: ['without_mask', 'with_mask']\n",
            "<PIL.Image.Image image mode=RGB size=159x242 at 0x7E17FD9145D0>\n",
            "Label for 'with_mask': 0\n",
            "Total images found: 4092\n",
            "Train samples: 2864 Validation samples: 613 Test samples: 615\n",
            "DataLoaders are ready for training, validation, and testing.\n",
            "2025-03-17 10:06:31,728 - wandb.wandb_agent - INFO - Running runs: ['yus59bap']\n",
            "2025-03-17 10:06:36,796 - wandb.wandb_agent - INFO - Cleaning up finished run: yus59bap\n",
            "2025-03-17 10:06:37,023 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2025-03-17 10:06:37,023 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tactivation_fn: relu\n",
            "\tbase_channels: 32\n",
            "\tbatch_size: 64\n",
            "\tepochs: 30\n",
            "\tlearning_rate: 0.005626087411545528\n",
            "\toptimizer: adam\n",
            "\tpatience: 5\n",
            "\tuse_scheduler: True\n",
            "\tweight_decay: 0.0007918409418353581\n",
            "2025-03-17 10:06:37,025 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --activation_fn=relu --base_channels=32 --batch_size=64 --epochs=30 --learning_rate=0.005626087411545528 --optimizer=adam --patience=5 --use_scheduler=True --weight_decay=0.0007918409418353581\n",
            "fatal: destination path 'Face-Mask-Detection' already exists and is not an empty directory.\n",
            "Dataset directories: ['without_mask', 'with_mask']\n",
            "<PIL.Image.Image image mode=RGB size=159x242 at 0x7B1754CD32D0>\n",
            "Label for 'with_mask': 0\n",
            "Total images found: 4092\n",
            "Train samples: 2864 Validation samples: 613 Test samples: 615\n",
            "DataLoaders are ready for training, validation, and testing.\n",
            "2025-03-17 10:06:42,036 - wandb.wandb_agent - INFO - Running runs: ['ojnmwdwc']\n"
          ]
        }
      ]
    }
  ]
}